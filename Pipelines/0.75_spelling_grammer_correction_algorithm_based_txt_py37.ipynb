{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3c08be2f",
   "metadata": {},
   "source": [
    "# clean and format the extracted text to be cleaners \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cc24723e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install pyLDAvis00"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7c1628a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c8972258",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Python_Functions.NLP_Data_Engineer_Functions import text_cleaning, stop_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ec91ece6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform edit distance in python\n",
    "#levemstain distance used to measure the infoamtion difference\n",
    "# https://stackabuse.com/levenshtein-distance-and-text-similarity-in-python/\n",
    "\n",
    "# String Similarity Measures\n",
    "def levenshtein(seq1, seq2):\n",
    "    size_x = len(seq1) + 1\n",
    "    size_y = len(seq2) + 1\n",
    "    matrix = np.zeros ((size_x, size_y))\n",
    "    for x in range(size_x):\n",
    "        matrix [x, 0] = x\n",
    "    for y in range(size_y):\n",
    "        matrix [0, y] = y\n",
    "\n",
    "    for x in range(1, size_x):\n",
    "        for y in range(1, size_y):\n",
    "            if seq1[x-1] == seq2[y-1]:\n",
    "                matrix [x,y] = min(\n",
    "                    matrix[x-1, y] + 1,\n",
    "                    matrix[x-1, y-1],\n",
    "                    matrix[x, y-1] + 1\n",
    "                )\n",
    "            else:\n",
    "                matrix [x,y] = min(\n",
    "                    matrix[x-1,y] + 1,\n",
    "                    matrix[x-1,y-1] + 1,\n",
    "                    matrix[x,y-1] + 1\n",
    "                )\n",
    "#     print (matrix)\n",
    "    return (matrix[size_x - 1, size_y - 1])\n",
    "# seq1 = 'I walk to the store and I bought milk'\n",
    "# seq2 =  'I was walking to the store and I bought milk.'\n",
    "\n",
    "# levenshtein(seq1, seq2)\n",
    "\n",
    "# return different words from 2 sentences\n",
    "def UncommonWords(A, B):\n",
    "  \n",
    "    # count will contain all the word counts\n",
    "    count = {}\n",
    "      \n",
    "    # insert words of string A to hash\n",
    "    for word in A.split():\n",
    "        count[word] = count.get(word, 0) + 1\n",
    "      \n",
    "    # insert words of string B to hash\n",
    "    for word in B.split():\n",
    "        count[word] = count.get(word, 0) + 1\n",
    "  \n",
    "    # return required list of words\n",
    "    return [word for word in count if count[word] == 1]\n",
    "\n",
    "# n-gram similarity measures: n-gram of a string s in any substring of s of length n. A simple measure would be to choose n and count the number of common n-grams between two strings s and t.\n",
    "# https://www.analyticsvidhya.com/blog/2021/09/what-are-n-grams-and-how-to-implement-them-in-python/\n",
    "\n",
    "# word counts\n",
    "\n",
    "def word_cnt_compare(sentence1, sentence2):\n",
    "    words1 = nltk.word_tokenize(sentence1) \n",
    "    words2 = nltk.word_tokenize(sentence2) \n",
    "    return len(words1) - len(words2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0165c787",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tokenized_sentences</th>\n",
       "      <th>sentence_level_timstamp_min_sec</th>\n",
       "      <th>sentence_level_timstamp_max_sec</th>\n",
       "      <th>sentence_level_timstamp_min_minute</th>\n",
       "      <th>sentence_level_timstamp_max_minute</th>\n",
       "      <th>audio_source</th>\n",
       "      <th>diff_ratio</th>\n",
       "      <th>info_loss_perc</th>\n",
       "      <th>main_topics</th>\n",
       "      <th>meta_file</th>\n",
       "      <th>reference_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>did you find an ant hill</td>\n",
       "      <td>11.666667</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.1944</td>\n",
       "      <td>0.3333</td>\n",
       "      <td>insects_intro_ant_v</td>\n",
       "      <td>0.721154</td>\n",
       "      <td>27.885</td>\n",
       "      <td>insect_ant</td>\n",
       "      <td>insects_intro_ant_t</td>\n",
       "      <td>['Ants are one of the most common insects that...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>the app that you see outside or only a small n...</td>\n",
       "      <td>23.333333</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.3889</td>\n",
       "      <td>0.6667</td>\n",
       "      <td>insects_intro_ant_v</td>\n",
       "      <td>0.721154</td>\n",
       "      <td>27.885</td>\n",
       "      <td>insect_ant</td>\n",
       "      <td>insects_intro_ant_t</td>\n",
       "      <td>['Ants are one of the most common insects that...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>these huge groups of ants are called calm he s...</td>\n",
       "      <td>40.476190</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.6746</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>insects_intro_ant_v</td>\n",
       "      <td>0.721154</td>\n",
       "      <td>27.885</td>\n",
       "      <td>insect_ant</td>\n",
       "      <td>insects_intro_ant_t</td>\n",
       "      <td>['Ants are one of the most common insects that...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>all of the worker ants all females</td>\n",
       "      <td>59.411765</td>\n",
       "      <td>62.0</td>\n",
       "      <td>0.9902</td>\n",
       "      <td>1.0333</td>\n",
       "      <td>insects_intro_ant_v</td>\n",
       "      <td>0.721154</td>\n",
       "      <td>27.885</td>\n",
       "      <td>insect_ant</td>\n",
       "      <td>insects_intro_ant_t</td>\n",
       "      <td>['Ants are one of the most common insects that...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>the meal ask job is the fertilized the queen t...</td>\n",
       "      <td>62.400000</td>\n",
       "      <td>71.5</td>\n",
       "      <td>1.0400</td>\n",
       "      <td>1.1917</td>\n",
       "      <td>insects_intro_ant_v</td>\n",
       "      <td>0.721154</td>\n",
       "      <td>27.885</td>\n",
       "      <td>insect_ant</td>\n",
       "      <td>insects_intro_ant_t</td>\n",
       "      <td>['Ants are one of the most common insects that...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 tokenized_sentences  \\\n",
       "0                           did you find an ant hill   \n",
       "1  the app that you see outside or only a small n...   \n",
       "2  these huge groups of ants are called calm he s...   \n",
       "3                 all of the worker ants all females   \n",
       "4  the meal ask job is the fertilized the queen t...   \n",
       "\n",
       "   sentence_level_timstamp_min_sec  sentence_level_timstamp_max_sec  \\\n",
       "0                        11.666667                             20.0   \n",
       "1                        23.333333                             40.0   \n",
       "2                        40.476190                             60.0   \n",
       "3                        59.411765                             62.0   \n",
       "4                        62.400000                             71.5   \n",
       "\n",
       "   sentence_level_timstamp_min_minute  sentence_level_timstamp_max_minute  \\\n",
       "0                              0.1944                              0.3333   \n",
       "1                              0.3889                              0.6667   \n",
       "2                              0.6746                              1.0000   \n",
       "3                              0.9902                              1.0333   \n",
       "4                              1.0400                              1.1917   \n",
       "\n",
       "          audio_source  diff_ratio  info_loss_perc main_topics  \\\n",
       "0  insects_intro_ant_v    0.721154          27.885  insect_ant   \n",
       "1  insects_intro_ant_v    0.721154          27.885  insect_ant   \n",
       "2  insects_intro_ant_v    0.721154          27.885  insect_ant   \n",
       "3  insects_intro_ant_v    0.721154          27.885  insect_ant   \n",
       "4  insects_intro_ant_v    0.721154          27.885  insect_ant   \n",
       "\n",
       "             meta_file                                     reference_text  \n",
       "0  insects_intro_ant_t  ['Ants are one of the most common insects that...  \n",
       "1  insects_intro_ant_t  ['Ants are one of the most common insects that...  \n",
       "2  insects_intro_ant_t  ['Ants are one of the most common insects that...  \n",
       "3  insects_intro_ant_t  ['Ants are one of the most common insects that...  \n",
       "4  insects_intro_ant_t  ['Ants are one of the most common insects that...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences_extracted_pd =  pd.read_csv(\"scraping_data/Targeted_Ouput/1_audio_sentences_timestamp_df.csv\")\n",
    "sentences_extracted_pd.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f1ef0eee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>video_file</th>\n",
       "      <th>raw_txt</th>\n",
       "      <th>main_topics</th>\n",
       "      <th>reference_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>insects_intro_ant_v</td>\n",
       "      <td>Did you find an ant hill. The app that you see...</td>\n",
       "      <td>insect_ant</td>\n",
       "      <td>['Ants are one of the most common insects that...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>birds_intro_tailor_bird_v</td>\n",
       "      <td>This is a girl named masha. She's sleeping and...</td>\n",
       "      <td>bird_tailorbird</td>\n",
       "      <td>['Tailorbird', 'Tailorbird- The Tailorbird has...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>birds_intro_peacock_v</td>\n",
       "      <td>Wow look at those feathers. The bird you found...</td>\n",
       "      <td>bird_peacock</td>\n",
       "      <td>['PEAFOWL', 'Peacock is the National bird of I...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>insects_intro_beetle_v</td>\n",
       "      <td>Beetles have a hard shell like armor. And i sa...</td>\n",
       "      <td>insect_beetle</td>\n",
       "      <td>['We see many insects around us. Some have win...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>birds_intro_flamingo_v</td>\n",
       "      <td>Let's learn about flamingos flamingos are tall...</td>\n",
       "      <td>bird_flamingo</td>\n",
       "      <td>['Flamingo', 'Flamingo is about 110 to 150 cm ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  video_file  \\\n",
       "0        insects_intro_ant_v   \n",
       "1  birds_intro_tailor_bird_v   \n",
       "2      birds_intro_peacock_v   \n",
       "3     insects_intro_beetle_v   \n",
       "4     birds_intro_flamingo_v   \n",
       "\n",
       "                                             raw_txt      main_topics  \\\n",
       "0  Did you find an ant hill. The app that you see...       insect_ant   \n",
       "1  This is a girl named masha. She's sleeping and...  bird_tailorbird   \n",
       "2  Wow look at those feathers. The bird you found...     bird_peacock   \n",
       "3  Beetles have a hard shell like armor. And i sa...    insect_beetle   \n",
       "4  Let's learn about flamingos flamingos are tall...    bird_flamingo   \n",
       "\n",
       "                                      reference_text  \n",
       "0  ['Ants are one of the most common insects that...  \n",
       "1  ['Tailorbird', 'Tailorbird- The Tailorbird has...  \n",
       "2  ['PEAFOWL', 'Peacock is the National bird of I...  \n",
       "3  ['We see many insects around us. Some have win...  \n",
       "4  ['Flamingo', 'Flamingo is about 110 to 150 cm ...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_extracted_pd = pd.read_csv(\"scraping_data/Targeted_Ouput/text_level_df.csv\")\n",
    "videos_files_lst = list(text_extracted_pd['video_file'])\n",
    "text_extracted_pd.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "01414d3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>video_file</th>\n",
       "      <th>raw_txt</th>\n",
       "      <th>main_topics</th>\n",
       "      <th>reference_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>insects_intro_ant_v</td>\n",
       "      <td>Did you find an ant hill. The app that you see...</td>\n",
       "      <td>insect_ant</td>\n",
       "      <td>['Ants are one of the most common insects that...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>birds_intro_tailor_bird_v</td>\n",
       "      <td>This is a girl named masha. She's sleeping and...</td>\n",
       "      <td>bird_tailorbird</td>\n",
       "      <td>['Tailorbird', 'Tailorbird- The Tailorbird has...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>birds_intro_peacock_v</td>\n",
       "      <td>Wow look at those feathers. The bird you found...</td>\n",
       "      <td>bird_peacock</td>\n",
       "      <td>['PEAFOWL', 'Peacock is the National bird of I...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>insects_intro_beetle_v</td>\n",
       "      <td>Beetles have a hard shell like armor. And i sa...</td>\n",
       "      <td>insect_beetle</td>\n",
       "      <td>['We see many insects around us. Some have win...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>birds_intro_flamingo_v</td>\n",
       "      <td>Let's learn about flamingos flamingos are tall...</td>\n",
       "      <td>bird_flamingo</td>\n",
       "      <td>['Flamingo', 'Flamingo is about 110 to 150 cm ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  video_file  \\\n",
       "0        insects_intro_ant_v   \n",
       "1  birds_intro_tailor_bird_v   \n",
       "2      birds_intro_peacock_v   \n",
       "3     insects_intro_beetle_v   \n",
       "4     birds_intro_flamingo_v   \n",
       "\n",
       "                                             raw_txt      main_topics  \\\n",
       "0  Did you find an ant hill. The app that you see...       insect_ant   \n",
       "1  This is a girl named masha. She's sleeping and...  bird_tailorbird   \n",
       "2  Wow look at those feathers. The bird you found...     bird_peacock   \n",
       "3  Beetles have a hard shell like armor. And i sa...    insect_beetle   \n",
       "4  Let's learn about flamingos flamingos are tall...    bird_flamingo   \n",
       "\n",
       "                                      reference_text  \n",
       "0  ['Ants are one of the most common insects that...  \n",
       "1  ['Tailorbird', 'Tailorbird- The Tailorbird has...  \n",
       "2  ['PEAFOWL', 'Peacock is the National bird of I...  \n",
       "3  ['We see many insects around us. Some have win...  \n",
       "4  ['Flamingo', 'Flamingo is about 110 to 150 cm ...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_extracted_pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6e52ba5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "files_identifiers = list(text_extracted_pd['video_file'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0456dc68",
   "metadata": {},
   "source": [
    "\n",
    "## Implement Text Correction Technqiue\n",
    "\n",
    "- Word might me wrong\n",
    "- Has one extra letter\n",
    "- Missing one letter\n",
    "- Has a single transposition i.e. a pair of adjacent letters in the word interchanged.\n",
    "\n",
    "- symspellpy: https://github.com/mammothb/symspellpy\n",
    "- grammerly API\n",
    "\n",
    "https://www.section.io/engineering-education/building-a-grammar-correction-python-app-with-gramformer-and-gradio/\n",
    "    \n",
    "https://github.com/PrithivirajDamodaran/Gramformer\n",
    "\n",
    "https://www.youtube.com/watch?v=yH36NQGp4NQ\n",
    "    \n",
    "https://towardsdatascience.com/extracting-speech-from-video-using-python-f0ec7e312d38\n",
    "\n",
    "https://github.com/hamelsmu/Seq2Seq_Tutorial/issues/1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4b39b328",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Based on the length of the sentences, levenshtain_scores, jaccard_scores, words_diff,\n",
    "# choose to use the original raw sentences vs corrected sentences\n",
    "\n",
    "# - if the sentences are = or less than 4 words, we keep the original raw sentences\n",
    "# - if levenshtain_scores, jaccard_scores, num_words_diff are 0, then go with the raw_text\n",
    "# - if the sentences are more than 4 words and word_diff > 10, go with the raw_text\n",
    "\n",
    "def version_select(txt1, txt2, count, ratio):\n",
    "    if count <= 4:\n",
    "        return txt1\n",
    "    else:\n",
    "        if ratio <= 0.1:\n",
    "            return txt2\n",
    "        else:\n",
    "            return txt1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "81a6876d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mikewu/opt/anaconda3/envs/python3.8/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "from gramformer import Gramformer\n",
    "import torch\n",
    "import en_core_web_sm\n",
    "from nltk.tokenize import word_tokenize\n",
    "nlp = spacy.blank(\"en\")\n",
    "nlp = en_core_web_sm.load()\n",
    "\n",
    "def set_seed(seed):\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "def Correct_Sentences(file_identifier, temp_txt):\n",
    "    set_seed(1212)\n",
    "    gf = Gramformer(models = 1, use_gpu=False) # 1=corrector, 2=detector\n",
    "    \n",
    "    sentences = sent_tokenize(temp_txt)\n",
    "    \n",
    "    raw_sentences =  sentences \n",
    "    corrected_sentences = []\n",
    "    Levenshtain_scores = []\n",
    "    Jaccard_scores = []\n",
    "    words_diff = []\n",
    "    for i in range(0, len(raw_sentences)):\n",
    "        print(i)\n",
    "        raw_sentence = raw_sentences[i]\n",
    "        corrected_sentence = list(gf.correct(raw_sentence, max_candidates=1))[0]\n",
    "        corrected_sentences.append(corrected_sentence )\n",
    "        Levenshtain_scores.append(levenshtein(seq1 = raw_sentence , seq2 = corrected_sentence))\n",
    "        Jaccard_scores.append(nltk.jaccard_distance(set(raw_sentence), set(corrected_sentence) ))\n",
    "        words_diff.append(word_cnt_compare(raw_sentence, corrected_sentence))\n",
    "        \n",
    "    # formulatae the corrected sentences back to txt chunk\n",
    "    start_txt = ''\n",
    "    for indx, sen in enumerate(corrected_sentences):\n",
    "        if indx == 0:\n",
    "            corrected_txt = start_txt.strip() + sen.strip()\n",
    "        else:\n",
    "            corrected_txt = corrected_txt.strip() + \" \" + sen.strip()\n",
    "    \n",
    "    # form dataframe from all the outputs\n",
    "    res_df = pd.DataFrame()\n",
    "    res_df[\"file_name\"] = [file_identifier] * len(corrected_sentences)\n",
    "    res_df[\"raw_txt\"] = [temp_txt] * len(corrected_sentences)\n",
    "    res_df[\"raw_sentences\"] = raw_sentences\n",
    "    res_df[\"corrected_sentences\"] = corrected_sentences\n",
    "    res_df[\"corrected_txt\"] = corrected_txt\n",
    "    res_df[\"sentences_levenshtain_scores\"] = Levenshtain_scores\n",
    "    res_df[\"sentences_jaccard_scores\"] = Jaccard_scores\n",
    "    res_df[\"sentences_num_words_diff\"] = words_diff\n",
    "    res_df[\"sentences_num_words_diff_abs\"] = np.abs(words_diff)\n",
    "    \n",
    "    raw_sentences_word_counts = [len(word_tokenize(i)) for i in list(res_df[\"raw_sentences\"])]\n",
    "    res_df[\"raw_sentences_word_counts\"] = raw_sentences_word_counts\n",
    "    res_df[\"correction_ratio\"] = res_df[\"sentences_num_words_diff_abs\"]/res_df[\"raw_sentences_word_counts\"]\n",
    "    \n",
    "\n",
    "    # select to keep the corewcted txt vs keep the raw_txt\n",
    "    res_df['final_corrected_version_sentences_txt'] = res_df.apply(lambda x: version_select(x.raw_sentences, x.corrected_sentences, x.correction_ratio, x.raw_sentences_word_counts ), axis=1)\n",
    "    \n",
    "    # formulatae the final corrected sentences back to txt chunk\n",
    "    start_txt = ''\n",
    "    selected = list(res_df['final_corrected_version_sentences_txt'])\n",
    "    for indx, sen in enumerate(selected):\n",
    "        if indx == 0:\n",
    "            final_txt = start_txt.strip() + sen.strip() \n",
    "        else:\n",
    "            final_txt = final_txt.strip() + \" \" + sen.strip()\n",
    "    \n",
    "    res_df['final_corrected_version_txt'] = final_txt\n",
    "    \n",
    "    return res_df\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "178c3995",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mikewu/opt/anaconda3/envs/python3.8/lib/python3.8/site-packages/tensorflow/python/framework/dtypes.py:513: DeprecationWarning: `np.object` is a deprecated alias for the builtin `object`. To silence this warning, use `object` by itself. Doing this will not modify any behavior and is safe. \n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  np.object,\n",
      "/Users/mikewu/opt/anaconda3/envs/python3.8/lib/python3.8/site-packages/tensorflow/python/framework/dtypes.py:521: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  np.bool,\n",
      "/Users/mikewu/opt/anaconda3/envs/python3.8/lib/python3.8/site-packages/tensorflow/python/framework/dtypes.py:555: DeprecationWarning: `np.object` is a deprecated alias for the builtin `object`. To silence this warning, use `object` by itself. Doing this will not modify any behavior and is safe. \n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  np.object,\n",
      "/Users/mikewu/opt/anaconda3/envs/python3.8/lib/python3.8/site-packages/tensorflow/python/framework/dtypes.py:565: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  np.bool,\n",
      "/Users/mikewu/opt/anaconda3/envs/python3.8/lib/python3.8/site-packages/tensorflow/python/framework/tensor_util.py:108: DeprecationWarning: `np.object` is a deprecated alias for the builtin `object`. To silence this warning, use `object` by itself. Doing this will not modify any behavior and is safe. \n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  np.object:\n",
      "/Users/mikewu/opt/anaconda3/envs/python3.8/lib/python3.8/site-packages/tensorflow/python/framework/tensor_util.py:110: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  np.bool:\n",
      "/Users/mikewu/opt/anaconda3/envs/python3.8/lib/python3.8/site-packages/tensorflow/python/ops/numpy_ops/np_random.py:95: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  def randint(low, high=None, size=None, dtype=onp.int):  # pylint: disable=missing-function-docstring\n",
      "/Users/mikewu/opt/anaconda3/envs/python3.8/lib/python3.8/site-packages/h5py/__init__.py:46: DeprecationWarning: `np.typeDict` is a deprecated alias for `np.sctypeDict`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "/Users/mikewu/opt/anaconda3/envs/python3.8/lib/python3.8/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:572: DeprecationWarning: `np.object` is a deprecated alias for the builtin `object`. To silence this warning, use `object` by itself. Doing this will not modify any behavior and is safe. \n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  (np.object, string),\n",
      "/Users/mikewu/opt/anaconda3/envs/python3.8/lib/python3.8/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:573: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  (np.bool, bool),\n",
      "/Users/mikewu/opt/anaconda3/envs/python3.8/lib/python3.8/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:597: DeprecationWarning: `np.object` is a deprecated alias for the builtin `object`. To silence this warning, use `object` by itself. Doing this will not modify any behavior and is safe. \n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  types_pb2.DT_STRING: np.object,\n",
      "/Users/mikewu/opt/anaconda3/envs/python3.8/lib/python3.8/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:601: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  types_pb2.DT_BOOL: np.bool,\n",
      "/Users/mikewu/opt/anaconda3/envs/python3.8/lib/python3.8/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:618: DeprecationWarning: `np.object` is a deprecated alias for the builtin `object`. To silence this warning, use `object` by itself. Doing this will not modify any behavior and is safe. \n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  types_pb2.DT_STRING_REF: np.object,\n",
      "/Users/mikewu/opt/anaconda3/envs/python3.8/lib/python3.8/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:623: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  types_pb2.DT_BOOL_REF: np.bool,\n",
      "/Users/mikewu/opt/anaconda3/envs/python3.8/lib/python3.8/site-packages/tensorboard/util/tensor_util.py:113: DeprecationWarning: `np.object` is a deprecated alias for the builtin `object`. To silence this warning, use `object` by itself. Doing this will not modify any behavior and is safe. \n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  np.object: SlowAppendObjectArrayToTensorProto,\n",
      "/Users/mikewu/opt/anaconda3/envs/python3.8/lib/python3.8/site-packages/tensorboard/util/tensor_util.py:114: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  np.bool: SlowAppendBoolArrayToTensorProto,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Gramformer] Grammar error correct/highlight model loaded..\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "[Gramformer] Grammar error correct/highlight model loaded..\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "[Gramformer] Grammar error correct/highlight model loaded..\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "[Gramformer] Grammar error correct/highlight model loaded..\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "[Gramformer] Grammar error correct/highlight model loaded..\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n"
     ]
    }
   ],
   "source": [
    "result_corrected_df = pd.DataFrame()\n",
    "for file in files_identifiers:\n",
    "    \n",
    "    temp_txt = text_extracted_pd[text_extracted_pd['video_file'] == file]['raw_txt'].values[0]\n",
    "    temp_pd = Correct_Sentences(file_identifier = file, temp_txt = temp_txt)\n",
    "    result_corrected_df = pd.concat([result_corrected_df, temp_pd ], axis = 0)\n",
    "    \n",
    "    \n",
    "result_corrected_df = result_corrected_df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a9ff7b6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_name</th>\n",
       "      <th>raw_txt</th>\n",
       "      <th>raw_sentences</th>\n",
       "      <th>corrected_sentences</th>\n",
       "      <th>corrected_txt</th>\n",
       "      <th>sentences_levenshtain_scores</th>\n",
       "      <th>sentences_jaccard_scores</th>\n",
       "      <th>sentences_num_words_diff</th>\n",
       "      <th>sentences_num_words_diff_abs</th>\n",
       "      <th>raw_sentences_word_counts</th>\n",
       "      <th>correction_ratio</th>\n",
       "      <th>final_corrected_version_sentences_txt</th>\n",
       "      <th>final_corrected_version_txt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>insects_intro_ant_v</td>\n",
       "      <td>Did you find an ant hill. The app that you see...</td>\n",
       "      <td>Did you find an ant hill.</td>\n",
       "      <td>Did you find an old hill?</td>\n",
       "      <td>Did you find an old hill? The app only detects...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Did you find an ant hill.</td>\n",
       "      <td>Did you find an ant hill. The app that you see...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>insects_intro_ant_v</td>\n",
       "      <td>Did you find an ant hill. The app that you see...</td>\n",
       "      <td>The app that you see outside or only a small n...</td>\n",
       "      <td>The app only detects a small number of the ant...</td>\n",
       "      <td>Did you find an old hill? The app only detects...</td>\n",
       "      <td>37.0</td>\n",
       "      <td>0.045455</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>20</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>The app that you see outside or only a small n...</td>\n",
       "      <td>Did you find an ant hill. The app that you see...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>insects_intro_ant_v</td>\n",
       "      <td>Did you find an ant hill. The app that you see...</td>\n",
       "      <td>These huge groups of ants are called calm he's...</td>\n",
       "      <td>These huge groups of ants are called \"Calmette...</td>\n",
       "      <td>Did you find an old hill? The app only detects...</td>\n",
       "      <td>49.0</td>\n",
       "      <td>0.161290</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>54</td>\n",
       "      <td>0.037037</td>\n",
       "      <td>These huge groups of ants are called calm he's...</td>\n",
       "      <td>Did you find an ant hill. The app that you see...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>insects_intro_ant_v</td>\n",
       "      <td>Did you find an ant hill. The app that you see...</td>\n",
       "      <td>All of the worker ants all females.</td>\n",
       "      <td>All of the workers are all females.</td>\n",
       "      <td>Did you find an old hill? The app only detects...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.062500</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>All of the worker ants all females.</td>\n",
       "      <td>Did you find an ant hill. The app that you see...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>insects_intro_ant_v</td>\n",
       "      <td>Did you find an ant hill. The app that you see...</td>\n",
       "      <td>The meal ask job is the fertilized the queen t...</td>\n",
       "      <td>The meal ask job is the fertilized queen they ...</td>\n",
       "      <td>Did you find an old hill? The app only detects...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>0.041667</td>\n",
       "      <td>The meal ask job is the fertilized the queen t...</td>\n",
       "      <td>Did you find an ant hill. The app that you see...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             file_name                                            raw_txt  \\\n",
       "0  insects_intro_ant_v  Did you find an ant hill. The app that you see...   \n",
       "1  insects_intro_ant_v  Did you find an ant hill. The app that you see...   \n",
       "2  insects_intro_ant_v  Did you find an ant hill. The app that you see...   \n",
       "3  insects_intro_ant_v  Did you find an ant hill. The app that you see...   \n",
       "4  insects_intro_ant_v  Did you find an ant hill. The app that you see...   \n",
       "\n",
       "                                       raw_sentences  \\\n",
       "0                          Did you find an ant hill.   \n",
       "1  The app that you see outside or only a small n...   \n",
       "2  These huge groups of ants are called calm he's...   \n",
       "3                All of the worker ants all females.   \n",
       "4  The meal ask job is the fertilized the queen t...   \n",
       "\n",
       "                                 corrected_sentences  \\\n",
       "0                          Did you find an old hill?   \n",
       "1  The app only detects a small number of the ant...   \n",
       "2  These huge groups of ants are called \"Calmette...   \n",
       "3                All of the workers are all females.   \n",
       "4  The meal ask job is the fertilized queen they ...   \n",
       "\n",
       "                                       corrected_txt  \\\n",
       "0  Did you find an old hill? The app only detects...   \n",
       "1  Did you find an old hill? The app only detects...   \n",
       "2  Did you find an old hill? The app only detects...   \n",
       "3  Did you find an old hill? The app only detects...   \n",
       "4  Did you find an old hill? The app only detects...   \n",
       "\n",
       "   sentences_levenshtain_scores  sentences_jaccard_scores  \\\n",
       "0                           4.0                  0.200000   \n",
       "1                          37.0                  0.045455   \n",
       "2                          49.0                  0.161290   \n",
       "3                           4.0                  0.062500   \n",
       "4                           4.0                  0.000000   \n",
       "\n",
       "   sentences_num_words_diff  sentences_num_words_diff_abs  \\\n",
       "0                         0                             0   \n",
       "1                         6                             6   \n",
       "2                         2                             2   \n",
       "3                         0                             0   \n",
       "4                         1                             1   \n",
       "\n",
       "   raw_sentences_word_counts  correction_ratio  \\\n",
       "0                          7          0.000000   \n",
       "1                         20          0.300000   \n",
       "2                         54          0.037037   \n",
       "3                          8          0.000000   \n",
       "4                         24          0.041667   \n",
       "\n",
       "               final_corrected_version_sentences_txt  \\\n",
       "0                          Did you find an ant hill.   \n",
       "1  The app that you see outside or only a small n...   \n",
       "2  These huge groups of ants are called calm he's...   \n",
       "3                All of the worker ants all females.   \n",
       "4  The meal ask job is the fertilized the queen t...   \n",
       "\n",
       "                         final_corrected_version_txt  \n",
       "0  Did you find an ant hill. The app that you see...  \n",
       "1  Did you find an ant hill. The app that you see...  \n",
       "2  Did you find an ant hill. The app that you see...  \n",
       "3  Did you find an ant hill. The app that you see...  \n",
       "4  Did you find an ant hill. The app that you see...  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_corrected_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "16f45f02",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Python_Functions.NLP_Data_Engineer_Functions import stop_words, text_cleaning\n",
    "\n",
    "raw_sentences_lst = list(result_corrected_df.raw_sentences)\n",
    "result_corrected_df[\"cleaned_raw_sentences\"] = [text_cleaning(i,stop_words = stop_words )[3][0] for i in raw_sentences_lst]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c0c8ab6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(123, 11)\n",
      "Index(['tokenized_sentences', 'sentence_level_timstamp_min_sec',\n",
      "       'sentence_level_timstamp_max_sec', 'sentence_level_timstamp_min_minute',\n",
      "       'sentence_level_timstamp_max_minute', 'audio_source', 'diff_ratio',\n",
      "       'info_loss_perc', 'main_topics', 'meta_file', 'reference_text'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(sentences_extracted_pd.shape)\n",
    "print(sentences_extracted_pd.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f9208974",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(125, 14)\n",
      "Index(['file_name', 'raw_txt', 'raw_sentences', 'corrected_sentences',\n",
      "       'corrected_txt', 'sentences_levenshtain_scores',\n",
      "       'sentences_jaccard_scores', 'sentences_num_words_diff',\n",
      "       'sentences_num_words_diff_abs', 'raw_sentences_word_counts',\n",
      "       'correction_ratio', 'final_corrected_version_sentences_txt',\n",
      "       'final_corrected_version_txt', 'cleaned_raw_sentences'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(result_corrected_df.shape)\n",
    "print(result_corrected_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "95c6acc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_merged = pd.merge(result_corrected_df, sentences_extracted_pd,  \\\n",
    "         'left', left_on = 'cleaned_raw_sentences', right_on = 'tokenized_sentences')\n",
    "\n",
    "temp_merged = temp_merged[temp_merged['tokenized_sentences'].notnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "79a32ae7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['file_name', 'raw_txt', 'raw_sentences', 'corrected_sentences',\n",
       "       'corrected_txt', 'sentences_levenshtain_scores',\n",
       "       'sentences_jaccard_scores', 'sentences_num_words_diff',\n",
       "       'sentences_num_words_diff_abs', 'raw_sentences_word_counts',\n",
       "       'correction_ratio', 'final_corrected_version_sentences_txt',\n",
       "       'final_corrected_version_txt', 'cleaned_raw_sentences',\n",
       "       'tokenized_sentences', 'sentence_level_timstamp_min_sec',\n",
       "       'sentence_level_timstamp_max_sec', 'sentence_level_timstamp_min_minute',\n",
       "       'sentence_level_timstamp_max_minute', 'audio_source', 'diff_ratio',\n",
       "       'info_loss_perc', 'main_topics', 'meta_file', 'reference_text'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_merged.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a5520729",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(123, 25)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_merged.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "89c2211f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Engineered the new, cleaned and selected sentences into whole new raw_txt, the export to the csv file\n",
    "\n",
    "temp_merged.to_csv(\"scraping_data/Targeted_Ouput/1_transcaript_txt_sentences_level_corrected_timestamp.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3.8",
   "language": "python",
   "name": "python3.8"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
