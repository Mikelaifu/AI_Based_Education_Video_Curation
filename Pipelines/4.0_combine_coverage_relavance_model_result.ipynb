{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d9a3b4ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5ef25b48",
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_lvl_cov_df = pd.read_csv(\"model_output_dataset/coverage_measure_output_sentences.csv\")\n",
    "txt_lvl_cov_df = pd.read_csv(\"model_output_dataset/coverage_measure_output_text.csv\")\n",
    "\n",
    "sent_lvl_relv_df = pd.read_csv(\"model_output_dataset/sentences_lvl_relevance_score_data.csv\")\n",
    "txt_lvl_relv_df = pd.read_csv(\"model_output_dataset/text_lvl_relevance_score_data.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb3d6b2a",
   "metadata": {},
   "source": [
    "## Rank the video again their main topics from combo of coverage + relevance score\n",
    "\n",
    "As we use te result of coverage to filter out some of the high quality video content to train set, we now need to filter out those videos for apple-to-apple ranking results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "14465d16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90\n",
      "72\n"
     ]
    }
   ],
   "source": [
    "print(txt_lvl_cov_df['Video_ID'].drop_duplicates().shape[0])\n",
    "print(txt_lvl_relv_df['Video_ID'].drop_duplicates().shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c4ba80a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "txt_lvl_cov_df_validate = pd.merge(txt_lvl_cov_df, txt_lvl_relv_df['Video_ID'].drop_duplicates(), 'inner', left_on = ['Video_ID'], right_on = ['Video_ID'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aed7d67b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--------------------------\n",
      "Under a main_topic insect_ant, top 10 videos\n",
      "ranked by total_relevance_score: \n",
      "\n",
      "Video rank 1 -- By Relevance score: 9SPixBok5ls <--- VS --> By Coverage score: 9SPixBok5ls \n",
      "Video rank 2 -- By Relevance score: insects_intro_ant_v <--- VS --> By Coverage score: cXUCUvcscXs \n",
      "Video rank 3 -- By Relevance score: A_hEZNxG_H8 <--- VS --> By Coverage score: A_hEZNxG_H8 \n",
      "Video rank 4 -- By Relevance score: vG-QZOTc5_Q <--- VS --> By Coverage score: insects_intro_ant_v \n",
      "Video rank 5 -- By Relevance score: 2S__fbCGwOM <--- VS --> By Coverage score: QNnmjyHPnbc \n",
      "Video rank 6 -- By Relevance score: HedZXw_hAbs <--- VS --> By Coverage score: kFiDThjUBTk \n",
      "Video rank 7 -- By Relevance score: pCxY70kPDnM <--- VS --> By Coverage score: NVT2vUQMKUc \n",
      "Video rank 8 -- By Relevance score: Rj67rHawDTg <--- VS --> By Coverage score: 2S__fbCGwOM \n",
      "Video rank 9 -- By Relevance score: QNnmjyHPnbc <--- VS --> By Coverage score: kBnmf1XlWdA \n",
      "Video rank 10 -- By Relevance score: 7_e0CA_nhaE <--- VS --> By Coverage score: pCxY70kPDnM \n",
      "\n",
      "common top videos rank differences from top 10 ranks:\n",
      "Video - insects_intro_ant_v: Relevance rank 2 <-- VS --> Coverage rank 4\n",
      "Video - QNnmjyHPnbc: Relevance rank 9 <-- VS --> Coverage rank 5\n",
      "Video - 2S__fbCGwOM: Relevance rank 5 <-- VS --> Coverage rank 8\n",
      "Video - A_hEZNxG_H8: Relevance rank 3 <-- VS --> Coverage rank 3\n",
      "Video - pCxY70kPDnM: Relevance rank 7 <-- VS --> Coverage rank 10\n",
      "Video - 9SPixBok5ls: Relevance rank 1 <-- VS --> Coverage rank 1\n",
      "\n",
      "--------------------------\n",
      "Under a main_topic insect_beetle, top 10 videos\n",
      "ranked by total_relevance_score: \n",
      "\n",
      "Video rank 1 -- By Relevance score: Ac68MQPkQrM <--- VS --> By Coverage score: veY5fyt66cg \n",
      "Video rank 2 -- By Relevance score: KWEkONjPc3k <--- VS --> By Coverage score: insects_intro_beetle_v \n",
      "Video rank 3 -- By Relevance score: DAlhbxGkanU <--- VS --> By Coverage score: 3166nK3Gym8 \n",
      "Video rank 4 -- By Relevance score: IfaItDqFr-w <--- VS --> By Coverage score: LoHXGtVIy20 \n",
      "Video rank 5 -- By Relevance score: 3166nK3Gym8 <--- VS --> By Coverage score: DAlhbxGkanU \n",
      "Video rank 6 -- By Relevance score: nFeh9VfV0z8 <--- VS --> By Coverage score: F1-PGtF81Is \n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [5]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m cov_video_ids \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(txt_lvl_cov_df_validate[txt_lvl_cov_df_validate[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmain_topics\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m topic][[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mVideo_ID\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmain_topics\u001b[39m\u001b[38;5;124m'\u001b[39m, \\\n\u001b[1;32m     16\u001b[0m                             \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAvg_Cosine_Similarity\u001b[39m\u001b[38;5;124m'\u001b[39m]]\u001b[38;5;241m.\u001b[39mdrop_duplicates()\u001b[38;5;241m.\u001b[39msort_values(by \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAvg_Cosine_Similarity\u001b[39m\u001b[38;5;124m'\u001b[39m, ascending \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m)\u001b[38;5;241m.\u001b[39mhead(\u001b[38;5;241m10\u001b[39m)[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mVideo_ID\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m# print the result for comparison\u001b[39;00m\n\u001b[0;32m---> 19\u001b[0m [\u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mVideo rank \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m -- By Relevance score: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m <--- VS --> By Coverage score: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(index\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m, relev_video_ids[index],  cov_video_ids[index] )) \u001b[38;5;28;01mfor\u001b[39;00m index \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(relev_video_ids) ) ]\n\u001b[1;32m     21\u001b[0m \u001b[38;5;66;03m# print out the rank difference (comment videos rank discrepency) rank between the common top 10 videos measure by both model\u001b[39;00m\n\u001b[1;32m     22\u001b[0m commen_vds \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mset\u001b[39m(relev_video_ids)\u001b[38;5;241m.\u001b[39mintersection(cov_video_ids))\n",
      "Input \u001b[0;32mIn [5]\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     15\u001b[0m cov_video_ids \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(txt_lvl_cov_df_validate[txt_lvl_cov_df_validate[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmain_topics\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m topic][[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mVideo_ID\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmain_topics\u001b[39m\u001b[38;5;124m'\u001b[39m, \\\n\u001b[1;32m     16\u001b[0m                             \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAvg_Cosine_Similarity\u001b[39m\u001b[38;5;124m'\u001b[39m]]\u001b[38;5;241m.\u001b[39mdrop_duplicates()\u001b[38;5;241m.\u001b[39msort_values(by \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAvg_Cosine_Similarity\u001b[39m\u001b[38;5;124m'\u001b[39m, ascending \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m)\u001b[38;5;241m.\u001b[39mhead(\u001b[38;5;241m10\u001b[39m)[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mVideo_ID\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m# print the result for comparison\u001b[39;00m\n\u001b[0;32m---> 19\u001b[0m [\u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mVideo rank \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m -- By Relevance score: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m <--- VS --> By Coverage score: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(index\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m, relev_video_ids[index],  \u001b[43mcov_video_ids\u001b[49m\u001b[43m[\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m]\u001b[49m )) \u001b[38;5;28;01mfor\u001b[39;00m index \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(relev_video_ids) ) ]\n\u001b[1;32m     21\u001b[0m \u001b[38;5;66;03m# print out the rank difference (comment videos rank discrepency) rank between the common top 10 videos measure by both model\u001b[39;00m\n\u001b[1;32m     22\u001b[0m commen_vds \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mset\u001b[39m(relev_video_ids)\u001b[38;5;241m.\u001b[39mintersection(cov_video_ids))\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "main_topics_lst = list(txt_lvl_relv_df['main_topic'].unique())\n",
    "\n",
    "for topic in main_topics_lst:\n",
    "    \n",
    "    print()\n",
    "    print('--------------------------')\n",
    "    print(\"Under a main_topic {}, top 10 videos\\nranked by total_relevance_score: \\n\".format(topic))\n",
    "    # rank top 10 video in ters of relevance\n",
    "    relev_video_ids = list(txt_lvl_relv_df[txt_lvl_relv_df['main_topic'] ==\\\n",
    "                                  topic][['Video_ID', 'main_topic', \\\n",
    "                                'total_txt_level_relevance_score']].drop_duplicates().sort_values(\\\n",
    "                                    by = 'total_txt_level_relevance_score', ascending = False).head(10)['Video_ID'])\n",
    "    \n",
    "    # rank top 10 video in ters of coverage\n",
    "    cov_video_ids = list(txt_lvl_cov_df_validate[txt_lvl_cov_df_validate['main_topics'] == topic][['Video_ID', 'main_topics', \\\n",
    "                                'Avg_Cosine_Similarity']].drop_duplicates().sort_values(by = 'Avg_Cosine_Similarity', ascending = False).head(10)['Video_ID'])\n",
    "    \n",
    "    # print the result for comparison\n",
    "    [print(\"Video rank {} -- By Relevance score: {} <--- VS --> By Coverage score: {} \".format(index+1, relev_video_ids[index],  cov_video_ids[index] )) for index in range(len(relev_video_ids) ) ]\n",
    "    \n",
    "    # print out the rank difference (comment videos rank discrepency) rank between the common top 10 videos measure by both model\n",
    "    commen_vds = list(set(relev_video_ids).intersection(cov_video_ids))\n",
    "    print()\n",
    "    print(\"common top videos rank differences from top 10 ranks:\")\n",
    "    for com_vd in commen_vds:\n",
    "        print(\"Video - {}: Relevance rank {} <-- VS --> Coverage rank {}\".format(com_vd, relev_video_ids.index(com_vd) + 1, cov_video_ids.index(com_vd) + 1))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12898a8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "txt_relav_cov_merge_df = pd.merge(txt_lvl_relv_df[['Video_ID', 'main_topic', 'total_txt_level_relevance_score']].drop_duplicates(),\n",
    "         txt_lvl_cov_df_validate[['Video_ID', 'main_topics', 'Avg_Cosine_Similarity']].drop_duplicates(),\n",
    "        'left', left_on = ['Video_ID', 'main_topic'], right_on = ['Video_ID', 'main_topics'] ).drop(\"main_topic\", axis = 1)\n",
    "\n",
    "txt_relav_cov_merge_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97d1f027",
   "metadata": {},
   "outputs": [],
   "source": [
    "### rank by relevance and coverage score at the same time \n",
    "\n",
    "main_topics_lst = list(txt_relav_cov_merge_df['main_topics'].unique())\n",
    "\n",
    "for topic in main_topics_lst:\n",
    "    print()\n",
    "    print('--------------------------')\n",
    "    print(\"Under a main_topic {}, top 10 videos\\nranked by both coverage then relevance: \\n\".format(topic))\n",
    "    # rank top 10 video in ters of relevance\n",
    "    topic_video_ids = list(txt_relav_cov_merge_df[txt_relav_cov_merge_df['main_topics'] ==\\\n",
    "                                  topic].drop_duplicates().sort_values(\\\n",
    "                                    by = ['Avg_Cosine_Similarity', 'total_txt_level_relevance_score' ], ascending = False).head(10)['Video_ID'])\n",
    "    # print the result \n",
    "    [print(\"Video rank {} -- By Coverage then Relevance score: {}\".format(index+1, topic_video_ids[index] )) for index in range(len(topic_video_ids) ) ]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a241a79",
   "metadata": {},
   "outputs": [],
   "source": [
    "### rank by avg of relevance score + coverage score \n",
    "\n",
    "txt_relav_cov_merge_df['text_lvl_relevance_coverage_mean_score'] = txt_relav_cov_merge_df[['total_txt_level_relevance_score','Avg_Cosine_Similarity']].mean(axis=1)\n",
    "\n",
    "main_topics_lst = list(txt_relav_cov_merge_df['main_topics'].unique())\n",
    "\n",
    "for topic in main_topics_lst:\n",
    "    print()\n",
    "    print('--------------------------')\n",
    "    print(\"Under a main_topic {}, top 10 videos (by video ids) \\nranked by both coverage & relevance: \\n\".format(topic))\n",
    "    # rank top 10 video in ters of relevance\n",
    "    topic_video_ids = list(txt_relav_cov_merge_df[txt_relav_cov_merge_df['main_topics'] ==\\\n",
    "                                  topic].drop_duplicates().sort_values(\\\n",
    "                                    by = ['text_lvl_relevance_coverage_mean_score' ], ascending = False).head(10)['Video_ID'])\n",
    "    # print the result \n",
    "    [print(\"Video rank {} -- By relevance_coverage_mean_score: {}\".format(index+1, topic_video_ids[index] )) for index in range(len(topic_video_ids) ) ]\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d2783a9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c351be2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cb1236b2",
   "metadata": {},
   "source": [
    "## Rank the Sentences from combo of coverage + relevance score\n",
    "\n",
    "As we use te result of coverage to filter out some of the high quality video content to train set, we now need to filter out those videos for apple-to-apple ranking results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "399b08e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_lvl_cov_df_validate = pd.merge(sent_lvl_cov_df, sent_lvl_relv_df['Video_ID'].drop_duplicates(), \\\n",
    "         'inner', left_on = ['Video_ID'], right_on = ['Video_ID'])\n",
    "\n",
    "sentence_lvl_cov_df_validate.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfe696fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_lvl_cov_df_validate.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6805013",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_lvl_cov_df_validate.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d61f1341",
   "metadata": {},
   "source": [
    "Start to compare the validation the result between coverage vs relevance model in sentence level\n",
    "\n",
    "given a video ID, what are their sentences quality rankings? relevance vs coverage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f05ce30c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# main_topics_lst = list(sent_lvl_relv_df['main_topic'].unique())\n",
    "video_id = 'insects_intro_ant_v'\n",
    "\n",
    "print('--------------------------')\n",
    "print(\"Under a Video {}, top 10 sentences\\nranked by Relevance Score: \\n\".format(video_id))\n",
    "# rank top 10 video in ters of relevance\n",
    "relev_sentences_rank = sent_lvl_relv_df[(sent_lvl_relv_df['Video_ID'] == video_id)][['final_corrected_version_sentences_txt', \\\n",
    "            'total_relevancy_score_proba_sentence',\\\n",
    "            'sentence_level_timstamp_min_sec', 'sentence_level_timstamp_max_sec']].drop_duplicates().sort_values(\\\n",
    "                                by = 'total_relevancy_score_proba_sentence', ascending = False).head(10).reset_index(drop = True).reset_index().rename(columns = {\"index\" : \"Rank\"})\n",
    "\n",
    "relev_sentences_rank[\"Rank_by_Relevance\"] = relev_sentences_rank[\"Rank\"]  + 1\n",
    "\n",
    "# rank top 10 video in ters of coverage\n",
    "cov_sentences_rank = sentence_lvl_cov_df_validate[(sentence_lvl_cov_df_validate['Video_ID'] == video_id)][['final_corrected_version_sentences_txt', \\\n",
    "        'Avg_Cosine_Similarity']].drop_duplicates().sort_values(by = 'Avg_Cosine_Similarity', ascending = False).head(10).reset_index(drop = True).reset_index().rename(columns = {\"index\" : \"Rank\"})\n",
    "\n",
    "cov_sentences_rank[\"Rank_by_Coverage\"] = cov_sentences_rank[\"Rank\"]  + 1\n",
    "# print(cov_sentences_rank[\"Rank\"])\n",
    "\n",
    "#     print(cov_sentences_rank)\n",
    "\n",
    "# print the result for comparison\n",
    "[print(\"\\nSentences rank {}:\\nBy Relevance score:\\n{}\\n <--- VS -->\\nBy Coverage Score:\\n {} \".format(index+1, relev_sentences_rank[relev_sentences_rank[\"Rank_by_Relevance\"] == index + 1 ]['final_corrected_version_sentences_txt'].values[0],  cov_sentences_rank[cov_sentences_rank[\"Rank_by_Coverage\"] == index + 1]['final_corrected_version_sentences_txt'].values[0] )) for index in range(10) ]\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11eba618",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print out the rank difference (comment videos rank discrepency) rank between the common top 10 sentences measure by both models\n",
    "common_sentences_df = pd.merge(relev_sentences_rank,cov_sentences_rank\\\n",
    "        , 'inner', left_on = ['final_corrected_version_sentences_txt'], right_on = ['final_corrected_version_sentences_txt'])\n",
    "print(\"Common top videos rank differences from top 10 ranks:\")\n",
    "print()\n",
    "commen_sents = list(common_sentences_df['final_corrected_version_sentences_txt'])\n",
    "relev_sentences_ranks = list(common_sentences_df[\"Rank_by_Relevance\"])\n",
    "cov_sentences_ranks = list(common_sentences_df['Rank_by_Coverage'])\n",
    "for com_sen in commen_sents:\n",
    "    print(\"\\nSentences :\\n{}\\nRelevance rank: {} <-- VS --> Coverage rank {}\".format(com_sen, common_sentences_df[common_sentences_df.final_corrected_version_sentences_txt == com_sen][\"Rank_by_Relevance\"].values[0], common_sentences_df[common_sentences_df.final_corrected_version_sentences_txt == com_sen][\"Rank_by_Coverage\"].values[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c354ea66",
   "metadata": {},
   "source": [
    "### rank the sentences when take the avg of relevance and coverage model with the time stamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6974c27c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_lvl_relv_cov_df = pd.merge(sent_lvl_relv_df, sentence_lvl_cov_df_validate, 'left', left_on = ['Video_ID','final_corrected_version_sentences_txt'], right_on = ['Video_ID','final_corrected_version_sentences_txt'] )\n",
    "\n",
    "sent_lvl_relv_cov_df['mean_relevance_coverage_score'] = sent_lvl_relv_cov_df[['total_relevancy_score_proba_sentence', 'Avg_Cosine_Similarity']].mean(axis = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13b7db8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# main_topics_lst = list(sent_lvl_relv_df['main_topic'].unique())\n",
    "video_id = 'insects_intro_ant_v'\n",
    "\n",
    "print('--------------------------')\n",
    "print(\"Under a Video {}, top 10 sentences\\nranked by Relevance + Coverage Score: \\n\".format(video_id))\n",
    "# rank top 10 video in ters of relevance\n",
    "sentences_rank = sent_lvl_relv_cov_df[(sent_lvl_relv_cov_df['Video_ID'] == video_id)][['final_corrected_version_sentences_txt', \\\n",
    "            'mean_relevance_coverage_score',\\\n",
    "            'sentence_level_timstamp_min_sec', 'sentence_level_timstamp_max_sec']].drop_duplicates().sort_values(\\\n",
    "                                by = 'mean_relevance_coverage_score', ascending = False).head(10).reset_index(drop = True).reset_index().rename(columns = {\"index\" : \"Rank\"})\n",
    "\n",
    "sentences_rank[\"Rank\"] = sentences_rank[\"Rank\"]  + 1\n",
    "\n",
    "# print the result for comparison\n",
    "[print(\"\\nRank: #{} Sentence: '{}'\\nSentence start time: {}s\\nSentences end time: {}s \".format(index+1, \\\n",
    "                                                                               sentences_rank[sentences_rank[\"Rank\"] == index + 1 ]['final_corrected_version_sentences_txt'].values[0],\\\n",
    "                                                                                np.round(sentences_rank[sentences_rank[\"Rank\"] == index + 1]['sentence_level_timstamp_min_sec'].values[0], 3),\\\n",
    "                                                                                    np.round(sentences_rank[sentences_rank[\"Rank\"] == index + 1]['sentence_level_timstamp_max_sec'].values[0], 3) )) for index in range(10) ]\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df91064a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences_rank"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3.8",
   "language": "python",
   "name": "python3.8"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "73ab8f18a964c091ea08c459db2b75173deba64e0452276272bf6fa8e3b9c883"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
